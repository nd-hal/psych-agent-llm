{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "def calculate_rouge_scores(results_df):\n",
    "    rouge = Rouge()\n",
    "    scores = []\n",
    "\n",
    "    for index, row in results_df.iterrows():\n",
    "        for question in ['Text_SubjectiveLit', 'Text_Anxiety', 'Text_Numeracy', 'Text_TrustPhys']:\n",
    "            generated_response = row[f\"{question} Generated\"]\n",
    "            true_label = row[f\"{question} True\"]\n",
    "\n",
    "            if isinstance(generated_response, str) and isinstance(true_label, str):\n",
    "                # Calculate ROUGE scores\n",
    "                score = rouge.get_scores(generated_response, true_label)\n",
    "\n",
    "                scores.append({\n",
    "                    'Sample Index': row['Sample Index'],\n",
    "                    'Condition': row['Condition'],\n",
    "                    'Question': question,\n",
    "                    'ROUGE-1': score[0]['rouge-1']['f'],\n",
    "                    'ROUGE-2': score[0]['rouge-2']['f'],\n",
    "                    'ROUGE-L': score[0]['rouge-l']['f'],\n",
    "                    'Generated Response': generated_response,\n",
    "                    'True Label': true_label\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    results_df = pd.read_csv('experiment_results.csv')\n",
    "    rouge_scores_df = calculate_rouge_scores(results_df)\n",
    "    print(rouge_scores_df)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
